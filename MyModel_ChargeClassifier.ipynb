{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import keras\n",
    "from keras.models import  Sequential\n",
    "from keras.layers import Activation, BatchNormalization\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.metrics import categorical_crossentropy\n",
    "\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import rdMolDescriptors, Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''DATA PREPARE'''\n",
    "#read data file\n",
    "with open('1k_SMILES_strings.txt') as f:\n",
    "    array_SMILES_train = f.readlines()\n",
    "with open('1k_SMILES_strings_charges.txt') as f:\n",
    "    array_charges_train = f.readlines()\n",
    "with open('10_SMILES_strings_test.txt') as f:\n",
    "    array_SMILES_test = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert SMILES strings into molecules\n",
    "mols_train = [Chem.rdmolfiles.MolFromSmiles(SMILES_string_train) for SMILES_string_train in array_SMILES_train]\n",
    "mols_test = [Chem.rdmolfiles.MolFromSmiles(SMILES_string_test) for SMILES_string_test in array_SMILES_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert molecules into fingerprints\n",
    "bi = {}\n",
    "fps_train = [rdMolDescriptors.GetMorganFingerprintAsBitVect(m_train,radius=2, bitInfo=bi, nBits=256) for m_train in mols_train]\n",
    "fps_test = [rdMolDescriptors.GetMorganFingerprintAsBitVect(m_test,radius=2, bitInfo=bi, nBits=256) for m_test in mols_test]\n",
    "#fingerprints--Morgan\n",
    "#what is the meaning of 'radius', 'bi'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert fingerprints into binary\n",
    "nparray_fps_train = []\n",
    "for fp in fps_train:\n",
    "    arr = np.zeros((1,),dtype = int)#zeros vector\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    nparray_fps_train.append(arr)\n",
    "nparray_fps_test = []\n",
    "for fp in fps_test:\n",
    "    arr = np.zeros((1,),dtype = int)#zeros vector\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    nparray_fps_test.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 109,684\n",
      "Trainable params: 109,652\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''MODEL BUILD'''\n",
    "#Neural Network Architechture\n",
    "model = Sequential([\n",
    "    Dense(256, input_shape=(256,), activation='relu'),\n",
    "    Dense(128, activation='sigmoid'),\n",
    "    Dense(64, activation='sigmoid'),\n",
    "    Dense(32, activation='sigmoid'),\n",
    "    Dense(16, activation='sigmoid'),\n",
    "    BatchNormalization(axis=1),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "900/900 [==============================] - 0s 542us/step - loss: 1.3863 - accuracy: 0.2433 - val_loss: 1.4290 - val_accuracy: 0.5900\n",
      "Epoch 2/100\n",
      "900/900 [==============================] - 0s 526us/step - loss: 1.3812 - accuracy: 0.3089 - val_loss: 1.4003 - val_accuracy: 0.5900\n",
      "Epoch 3/100\n",
      "900/900 [==============================] - 0s 494us/step - loss: 1.3754 - accuracy: 0.3756 - val_loss: 1.3865 - val_accuracy: 0.5900\n",
      "Epoch 4/100\n",
      "900/900 [==============================] - 0s 484us/step - loss: 1.3705 - accuracy: 0.4244 - val_loss: 1.3787 - val_accuracy: 0.5900\n",
      "Epoch 5/100\n",
      "900/900 [==============================] - 0s 515us/step - loss: 1.3650 - accuracy: 0.4800 - val_loss: 1.3719 - val_accuracy: 0.5900\n",
      "Epoch 6/100\n",
      "900/900 [==============================] - 0s 514us/step - loss: 1.3577 - accuracy: 0.5456 - val_loss: 1.3642 - val_accuracy: 0.5900\n",
      "Epoch 7/100\n",
      "900/900 [==============================] - 1s 571us/step - loss: 1.3516 - accuracy: 0.5878 - val_loss: 1.3555 - val_accuracy: 0.5700\n",
      "Epoch 8/100\n",
      "900/900 [==============================] - 1s 608us/step - loss: 1.3447 - accuracy: 0.6367 - val_loss: 1.3456 - val_accuracy: 0.6200\n",
      "Epoch 9/100\n",
      "900/900 [==============================] - 0s 549us/step - loss: 1.3376 - accuracy: 0.6622 - val_loss: 1.3369 - val_accuracy: 0.6500\n",
      "Epoch 10/100\n",
      "900/900 [==============================] - 1s 556us/step - loss: 1.3277 - accuracy: 0.7033 - val_loss: 1.3276 - val_accuracy: 0.7100\n",
      "Epoch 11/100\n",
      "900/900 [==============================] - 0s 526us/step - loss: 1.3191 - accuracy: 0.7156 - val_loss: 1.3178 - val_accuracy: 0.7100\n",
      "Epoch 12/100\n",
      "900/900 [==============================] - 0s 530us/step - loss: 1.3086 - accuracy: 0.7422 - val_loss: 1.3097 - val_accuracy: 0.7200\n",
      "Epoch 13/100\n",
      "900/900 [==============================] - 1s 676us/step - loss: 1.2959 - accuracy: 0.7622 - val_loss: 1.2993 - val_accuracy: 0.7200\n",
      "Epoch 14/100\n",
      "900/900 [==============================] - 0s 516us/step - loss: 1.2831 - accuracy: 0.7678 - val_loss: 1.2903 - val_accuracy: 0.7300\n",
      "Epoch 15/100\n",
      "900/900 [==============================] - 0s 520us/step - loss: 1.2685 - accuracy: 0.7756 - val_loss: 1.2785 - val_accuracy: 0.7300\n",
      "Epoch 16/100\n",
      "900/900 [==============================] - 0s 500us/step - loss: 1.2535 - accuracy: 0.7889 - val_loss: 1.2668 - val_accuracy: 0.7300\n",
      "Epoch 17/100\n",
      "900/900 [==============================] - 0s 521us/step - loss: 1.2350 - accuracy: 0.8000 - val_loss: 1.2526 - val_accuracy: 0.7500\n",
      "Epoch 18/100\n",
      "900/900 [==============================] - 1s 598us/step - loss: 1.2124 - accuracy: 0.8033 - val_loss: 1.2389 - val_accuracy: 0.7500\n",
      "Epoch 19/100\n",
      "900/900 [==============================] - 1s 639us/step - loss: 1.1868 - accuracy: 0.7989 - val_loss: 1.2232 - val_accuracy: 0.7500\n",
      "Epoch 20/100\n",
      "900/900 [==============================] - 0s 509us/step - loss: 1.1710 - accuracy: 0.7967 - val_loss: 1.2054 - val_accuracy: 0.7500\n",
      "Epoch 21/100\n",
      "900/900 [==============================] - 0s 498us/step - loss: 1.1394 - accuracy: 0.8067 - val_loss: 1.1877 - val_accuracy: 0.7500\n",
      "Epoch 22/100\n",
      "900/900 [==============================] - 0s 499us/step - loss: 1.1045 - accuracy: 0.8278 - val_loss: 1.1659 - val_accuracy: 0.7400\n",
      "Epoch 23/100\n",
      "900/900 [==============================] - 0s 507us/step - loss: 1.0683 - accuracy: 0.8133 - val_loss: 1.1459 - val_accuracy: 0.7400\n",
      "Epoch 24/100\n",
      "900/900 [==============================] - 1s 572us/step - loss: 1.0322 - accuracy: 0.8156 - val_loss: 1.1235 - val_accuracy: 0.7400\n",
      "Epoch 25/100\n",
      "900/900 [==============================] - 1s 580us/step - loss: 0.9992 - accuracy: 0.8300 - val_loss: 1.1001 - val_accuracy: 0.7700\n",
      "Epoch 26/100\n",
      "900/900 [==============================] - 1s 597us/step - loss: 0.9833 - accuracy: 0.8322 - val_loss: 1.0811 - val_accuracy: 0.7500\n",
      "Epoch 27/100\n",
      "900/900 [==============================] - 1s 609us/step - loss: 0.9445 - accuracy: 0.8244 - val_loss: 1.0599 - val_accuracy: 0.7500\n",
      "Epoch 28/100\n",
      "900/900 [==============================] - 1s 649us/step - loss: 0.9011 - accuracy: 0.8378 - val_loss: 1.0394 - val_accuracy: 0.7500\n",
      "Epoch 29/100\n",
      "900/900 [==============================] - 1s 884us/step - loss: 0.8878 - accuracy: 0.8189 - val_loss: 1.0186 - val_accuracy: 0.7500\n",
      "Epoch 30/100\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.8496 - accuracy: 0.8278 - val_loss: 1.0017 - val_accuracy: 0.7400\n",
      "Epoch 31/100\n",
      "900/900 [==============================] - 1s 729us/step - loss: 0.8222 - accuracy: 0.8411 - val_loss: 0.9838 - val_accuracy: 0.7500\n",
      "Epoch 32/100\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.7934 - accuracy: 0.8456 - val_loss: 0.9626 - val_accuracy: 0.7500\n",
      "Epoch 33/100\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.7703 - accuracy: 0.8533 - val_loss: 0.9433 - val_accuracy: 0.7500\n",
      "Epoch 34/100\n",
      "900/900 [==============================] - 1s 685us/step - loss: 0.7746 - accuracy: 0.8411 - val_loss: 0.9326 - val_accuracy: 0.7500\n",
      "Epoch 35/100\n",
      "900/900 [==============================] - 1s 653us/step - loss: 0.7303 - accuracy: 0.8411 - val_loss: 0.9181 - val_accuracy: 0.7500\n",
      "Epoch 36/100\n",
      "900/900 [==============================] - 1s 697us/step - loss: 0.7046 - accuracy: 0.8622 - val_loss: 0.9009 - val_accuracy: 0.7500\n",
      "Epoch 37/100\n",
      "900/900 [==============================] - 1s 622us/step - loss: 0.6807 - accuracy: 0.8622 - val_loss: 0.8887 - val_accuracy: 0.7400\n",
      "Epoch 38/100\n",
      "900/900 [==============================] - 1s 704us/step - loss: 0.6594 - accuracy: 0.8711 - val_loss: 0.8772 - val_accuracy: 0.7400\n",
      "Epoch 39/100\n",
      "900/900 [==============================] - 1s 618us/step - loss: 0.6495 - accuracy: 0.8644 - val_loss: 0.8641 - val_accuracy: 0.7400\n",
      "Epoch 40/100\n",
      "900/900 [==============================] - 1s 576us/step - loss: 0.6366 - accuracy: 0.8633 - val_loss: 0.8539 - val_accuracy: 0.7500\n",
      "Epoch 41/100\n",
      "900/900 [==============================] - 1s 656us/step - loss: 0.6079 - accuracy: 0.8767 - val_loss: 0.8408 - val_accuracy: 0.7500\n",
      "Epoch 42/100\n",
      "900/900 [==============================] - 1s 862us/step - loss: 0.6073 - accuracy: 0.8578 - val_loss: 0.8306 - val_accuracy: 0.7500\n",
      "Epoch 43/100\n",
      "900/900 [==============================] - 1s 622us/step - loss: 0.5997 - accuracy: 0.8611 - val_loss: 0.8219 - val_accuracy: 0.7500\n",
      "Epoch 44/100\n",
      "900/900 [==============================] - 1s 614us/step - loss: 0.5784 - accuracy: 0.8633 - val_loss: 0.8137 - val_accuracy: 0.7500\n",
      "Epoch 45/100\n",
      "900/900 [==============================] - 1s 645us/step - loss: 0.5679 - accuracy: 0.8767 - val_loss: 0.8080 - val_accuracy: 0.7500\n",
      "Epoch 46/100\n",
      "900/900 [==============================] - 1s 815us/step - loss: 0.5737 - accuracy: 0.8667 - val_loss: 0.8048 - val_accuracy: 0.7600\n",
      "Epoch 47/100\n",
      "900/900 [==============================] - 1s 663us/step - loss: 0.5418 - accuracy: 0.8733 - val_loss: 0.7919 - val_accuracy: 0.7500\n",
      "Epoch 48/100\n",
      "900/900 [==============================] - 1s 675us/step - loss: 0.5832 - accuracy: 0.8544 - val_loss: 0.7885 - val_accuracy: 0.7500\n",
      "Epoch 49/100\n",
      "900/900 [==============================] - 1s 690us/step - loss: 0.5259 - accuracy: 0.8878 - val_loss: 0.7819 - val_accuracy: 0.7600\n",
      "Epoch 50/100\n",
      "900/900 [==============================] - 1s 678us/step - loss: 0.5260 - accuracy: 0.8844 - val_loss: 0.7747 - val_accuracy: 0.7600\n",
      "Epoch 51/100\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.4997 - accuracy: 0.8944 - val_loss: 0.7703 - val_accuracy: 0.7600\n",
      "Epoch 52/100\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.5032 - accuracy: 0.8789 - val_loss: 0.7653 - val_accuracy: 0.7600\n",
      "Epoch 53/100\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.5079 - accuracy: 0.8800 - val_loss: 0.7600 - val_accuracy: 0.7600\n",
      "Epoch 54/100\n",
      "900/900 [==============================] - 1s 790us/step - loss: 0.4802 - accuracy: 0.8989 - val_loss: 0.7504 - val_accuracy: 0.7500\n",
      "Epoch 55/100\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.4676 - accuracy: 0.8978 - val_loss: 0.7483 - val_accuracy: 0.7600\n",
      "Epoch 56/100\n",
      "900/900 [==============================] - 1s 727us/step - loss: 0.4868 - accuracy: 0.8778 - val_loss: 0.7437 - val_accuracy: 0.7600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "900/900 [==============================] - 1s 738us/step - loss: 0.4638 - accuracy: 0.8956 - val_loss: 0.7344 - val_accuracy: 0.7600\n",
      "Epoch 58/100\n",
      "900/900 [==============================] - 1s 735us/step - loss: 0.4466 - accuracy: 0.8944 - val_loss: 0.7324 - val_accuracy: 0.7600\n",
      "Epoch 59/100\n",
      "900/900 [==============================] - 1s 654us/step - loss: 0.4399 - accuracy: 0.9122 - val_loss: 0.7270 - val_accuracy: 0.7600\n",
      "Epoch 60/100\n",
      "900/900 [==============================] - 1s 723us/step - loss: 0.4517 - accuracy: 0.8944 - val_loss: 0.7288 - val_accuracy: 0.7600\n",
      "Epoch 61/100\n",
      "900/900 [==============================] - 1s 725us/step - loss: 0.4269 - accuracy: 0.9033 - val_loss: 0.7231 - val_accuracy: 0.7500\n",
      "Epoch 62/100\n",
      "900/900 [==============================] - 1s 648us/step - loss: 0.4388 - accuracy: 0.8989 - val_loss: 0.7198 - val_accuracy: 0.7600\n",
      "Epoch 63/100\n",
      "900/900 [==============================] - 1s 651us/step - loss: 0.4211 - accuracy: 0.9056 - val_loss: 0.7169 - val_accuracy: 0.7500\n",
      "Epoch 64/100\n",
      "900/900 [==============================] - 1s 656us/step - loss: 0.4243 - accuracy: 0.8989 - val_loss: 0.7128 - val_accuracy: 0.7500\n",
      "Epoch 65/100\n",
      "900/900 [==============================] - 1s 655us/step - loss: 0.4281 - accuracy: 0.8956 - val_loss: 0.7065 - val_accuracy: 0.7500\n",
      "Epoch 66/100\n",
      "900/900 [==============================] - 1s 718us/step - loss: 0.4255 - accuracy: 0.9022 - val_loss: 0.7006 - val_accuracy: 0.7600\n",
      "Epoch 67/100\n",
      "900/900 [==============================] - 1s 720us/step - loss: 0.4142 - accuracy: 0.9000 - val_loss: 0.6985 - val_accuracy: 0.7600\n",
      "Epoch 68/100\n",
      "900/900 [==============================] - 1s 667us/step - loss: 0.4270 - accuracy: 0.8933 - val_loss: 0.7009 - val_accuracy: 0.7400\n",
      "Epoch 69/100\n",
      "900/900 [==============================] - 1s 691us/step - loss: 0.3886 - accuracy: 0.9056 - val_loss: 0.6988 - val_accuracy: 0.7300\n",
      "Epoch 70/100\n",
      "900/900 [==============================] - 1s 654us/step - loss: 0.3892 - accuracy: 0.9067 - val_loss: 0.6937 - val_accuracy: 0.7400\n",
      "Epoch 71/100\n",
      "900/900 [==============================] - 1s 682us/step - loss: 0.4047 - accuracy: 0.8967 - val_loss: 0.6871 - val_accuracy: 0.7500\n",
      "Epoch 72/100\n",
      "900/900 [==============================] - 1s 671us/step - loss: 0.3767 - accuracy: 0.9189 - val_loss: 0.6891 - val_accuracy: 0.7400\n",
      "Epoch 73/100\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.3789 - accuracy: 0.9111 - val_loss: 0.6880 - val_accuracy: 0.7400\n",
      "Epoch 74/100\n",
      "900/900 [==============================] - 1s 596us/step - loss: 0.3521 - accuracy: 0.9244 - val_loss: 0.6889 - val_accuracy: 0.7400\n",
      "Epoch 75/100\n",
      "900/900 [==============================] - 0s 539us/step - loss: 0.3649 - accuracy: 0.9144 - val_loss: 0.6831 - val_accuracy: 0.7500\n",
      "Epoch 76/100\n",
      "900/900 [==============================] - 1s 569us/step - loss: 0.3544 - accuracy: 0.9189 - val_loss: 0.6784 - val_accuracy: 0.7600\n",
      "Epoch 77/100\n",
      "900/900 [==============================] - 1s 573us/step - loss: 0.3529 - accuracy: 0.9122 - val_loss: 0.6745 - val_accuracy: 0.7600\n",
      "Epoch 78/100\n",
      "900/900 [==============================] - 1s 559us/step - loss: 0.3531 - accuracy: 0.9167 - val_loss: 0.6746 - val_accuracy: 0.7600\n",
      "Epoch 79/100\n",
      "900/900 [==============================] - 0s 534us/step - loss: 0.3795 - accuracy: 0.9111 - val_loss: 0.6657 - val_accuracy: 0.7600\n",
      "Epoch 80/100\n",
      "900/900 [==============================] - 1s 574us/step - loss: 0.3640 - accuracy: 0.9144 - val_loss: 0.6620 - val_accuracy: 0.7600\n",
      "Epoch 81/100\n",
      "900/900 [==============================] - 1s 580us/step - loss: 0.3384 - accuracy: 0.9211 - val_loss: 0.6670 - val_accuracy: 0.7500\n",
      "Epoch 82/100\n",
      "900/900 [==============================] - 1s 583us/step - loss: 0.3630 - accuracy: 0.9144 - val_loss: 0.6649 - val_accuracy: 0.7500\n",
      "Epoch 83/100\n",
      "900/900 [==============================] - 0s 553us/step - loss: 0.3418 - accuracy: 0.9211 - val_loss: 0.6584 - val_accuracy: 0.7600\n",
      "Epoch 84/100\n",
      "900/900 [==============================] - 1s 647us/step - loss: 0.3274 - accuracy: 0.9278 - val_loss: 0.6582 - val_accuracy: 0.7500\n",
      "Epoch 85/100\n",
      "900/900 [==============================] - 1s 563us/step - loss: 0.3387 - accuracy: 0.9189 - val_loss: 0.6500 - val_accuracy: 0.7600\n",
      "Epoch 86/100\n",
      "900/900 [==============================] - 0s 507us/step - loss: 0.3476 - accuracy: 0.9233 - val_loss: 0.6510 - val_accuracy: 0.7500\n",
      "Epoch 87/100\n",
      "900/900 [==============================] - 0s 460us/step - loss: 0.3244 - accuracy: 0.9233 - val_loss: 0.6538 - val_accuracy: 0.7500\n",
      "Epoch 88/100\n",
      "900/900 [==============================] - 0s 482us/step - loss: 0.3346 - accuracy: 0.9233 - val_loss: 0.6489 - val_accuracy: 0.7500\n",
      "Epoch 89/100\n",
      "900/900 [==============================] - 0s 488us/step - loss: 0.3186 - accuracy: 0.9289 - val_loss: 0.6499 - val_accuracy: 0.7500\n",
      "Epoch 90/100\n",
      "900/900 [==============================] - 0s 497us/step - loss: 0.3099 - accuracy: 0.9300 - val_loss: 0.6481 - val_accuracy: 0.7500\n",
      "Epoch 91/100\n",
      "900/900 [==============================] - 0s 473us/step - loss: 0.3070 - accuracy: 0.9378 - val_loss: 0.6475 - val_accuracy: 0.7500\n",
      "Epoch 92/100\n",
      "900/900 [==============================] - 0s 476us/step - loss: 0.3081 - accuracy: 0.9289 - val_loss: 0.6523 - val_accuracy: 0.7500\n",
      "Epoch 93/100\n",
      "900/900 [==============================] - 0s 497us/step - loss: 0.3078 - accuracy: 0.9367 - val_loss: 0.6485 - val_accuracy: 0.7500\n",
      "Epoch 94/100\n",
      "900/900 [==============================] - ETA: 0s - loss: 0.2837 - accuracy: 0.94 - 0s 497us/step - loss: 0.2878 - accuracy: 0.9389 - val_loss: 0.6487 - val_accuracy: 0.7400\n",
      "Epoch 95/100\n",
      "900/900 [==============================] - 0s 503us/step - loss: 0.2982 - accuracy: 0.9278 - val_loss: 0.6453 - val_accuracy: 0.7400\n",
      "Epoch 96/100\n",
      "900/900 [==============================] - 0s 453us/step - loss: 0.2890 - accuracy: 0.9278 - val_loss: 0.6476 - val_accuracy: 0.7400\n",
      "Epoch 97/100\n",
      "900/900 [==============================] - 0s 503us/step - loss: 0.2882 - accuracy: 0.9433 - val_loss: 0.6421 - val_accuracy: 0.7400\n",
      "Epoch 98/100\n",
      "900/900 [==============================] - 0s 478us/step - loss: 0.2987 - accuracy: 0.9322 - val_loss: 0.6377 - val_accuracy: 0.7400\n",
      "Epoch 99/100\n",
      "900/900 [==============================] - 0s 486us/step - loss: 0.3207 - accuracy: 0.9111 - val_loss: 0.6260 - val_accuracy: 0.7500\n",
      "Epoch 100/100\n",
      "900/900 [==============================] - 0s 470us/step - loss: 0.3383 - accuracy: 0.9111 - val_loss: 0.6325 - val_accuracy: 0.7400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x25b50f4b550>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.00001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#Train the model\n",
    "model.fit(np.array(nparray_fps_train), np.array(array_charges_train), validation_split=0.1, batch_size=10, epochs=100, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 600us/step\n"
     ]
    }
   ],
   "source": [
    "#Predict new molecule charges\n",
    "predictions = model.predict(np.array(nparray_fps_test), batch_size=1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "charge: 0  possibility:  0.79426265\n",
      "charge: 1  possibility:  0.9309378\n",
      "charge: -1  possibility:  0.94840187\n",
      "charge: 1  possibility:  0.9655982\n",
      "charge: 1  possibility:  0.85117674\n",
      "charge: 1  possibility:  0.8405196\n",
      "charge: -1  possibility:  0.8367821\n",
      "charge: 1  possibility:  0.8486453\n",
      "charge: 0  possibility:  0.8785551\n",
      "charge: 1  possibility:  0.9571373\n"
     ]
    }
   ],
   "source": [
    "#Print the charge predictions\n",
    "values = []\n",
    "possib = []\n",
    "for prediction in predictions:\n",
    "    prediction = list(prediction)\n",
    "    values.append(prediction.index(max(prediction)))\n",
    "    possib.append(prediction[values[-1]])\n",
    "def switch(value):\n",
    "    case = {\n",
    "        0 : '0',\n",
    "        1 : '1',\n",
    "        2 : '-1',\n",
    "        3 : '-2',\n",
    "        4 : '-3'\n",
    "    }\n",
    "    return case.get(value, None)\n",
    "for i in range(len(values)):\n",
    "    print('charge:', switch(values[i]),' possibility: ',possib[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''default parameters\n",
    "charge: 0  possibility:  0.79426265\n",
    "charge: 1  possibility:  0.9309378\n",
    "charge: -1  possibility:  0.94840187\n",
    "charge: 1  possibility:  0.9655982\n",
    "charge: 1  possibility:  0.85117674\n",
    "charge: 1  possibility:  0.8405196\n",
    "charge: -1  possibility:  0.8367821\n",
    "charge: 1  possibility:  0.8486453\n",
    "charge: 0  possibility:  0.8785551\n",
    "charge: 1  possibility:  0.9571373\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cheminfo]",
   "language": "python",
   "name": "conda-env-cheminfo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
